{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14af9e78",
   "metadata": {},
   "source": [
    "\n",
    "# Install and import required libraries\n",
    "We install open-source Python packages (Hugging Face Transformers, Datasets, Plotly, etc.)\n",
    "and import them. These tools allow us to:\n",
    "- Load and process text data\n",
    "- Fine-tune pre-trained AI models\n",
    "- Visualize results with interactive charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e14c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets transformers torch accelerate evaluate scikit-learn plotly kaggle\n",
    "\n",
    "import pandas as pd, numpy as np, re, warnings\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from transformers import pipeline\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c910ed7",
   "metadata": {},
   "source": [
    "# Download financial and Bitcoin tweet datasets\n",
    "We authenticate with Kaggle and download two open-source datasets:\n",
    "1. **Financial Sentiment Dataset** (~5.8k labeled sentences: Positive/Negative/Neutral)  \n",
    "   → Used to train our sentiment classifier\n",
    "2. **Bitcoin Twitter Dataset** (~1M tweets with timestamps)  \n",
    "   → Used to analyze real trader sentiment over time\n",
    "\n",
    "We sample 10,000 tweets for fast inference while preserving date range (2021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a1bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()                     # upload kaggle.json\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp {list(uploaded.keys())[0]} ~/.kaggle/kaggle.json\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# 1. Labeled financial data\n",
    "!kaggle datasets download -d sbhatti/financial-sentiment-analysis -p /content --unzip\n",
    "df_labeled = pd.read_csv('/content/data.csv')\n",
    "df_labeled = df_labeled[['Sentence','Sentiment']].rename(columns={'Sentence':'text','Sentiment':'label'})\n",
    "df_labeled['label'] = df_labeled['label'].str.lower().map({'positive':0, 'negative':1, 'neutral':2})\n",
    "df_labeled = df_labeled.dropna()\n",
    "print(\"Labeled shape:\", df_labeled.shape)\n",
    "print(df_labeled['label'].value_counts())\n",
    "\n",
    "# 2. Bitcoin tweets\n",
    "!kaggle datasets download -d gautamchettiar/bitcoin-sentiment-analysis-twitter-data -p /content --unzip\n",
    "df_btc = pd.read_csv('/content/bitcoin_tweets1000000.csv', encoding='latin-1')\n",
    "df_btc = df_btc[['date','text']].dropna()\n",
    "df_btc = df_btc.sample(n=10000, random_state=42)\n",
    "df_btc['date'] = pd.to_datetime(df_btc['date'])\n",
    "print(\"BTC sample shape:\", df_btc.shape)\n",
    "print(\"Date range:\", df_btc['date'].min(), \"→\", df_btc['date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449137d6",
   "metadata": {},
   "source": [
    "# Clean text by removing noise\n",
    "We remove URLs, mentions (@user), hashtags, special characters, and short/irrelevant text.  \n",
    "This ensures:\n",
    "- The model focuses on meaningful words\n",
    "- No junk affects model performance\n",
    "- Consistent input format for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf10aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(txt):\n",
    "    txt = re.sub(r'http\\S+|www\\S+|https\\S+', '', txt, flags=re.MULTILINE)\n",
    "    txt = re.sub(r'@\\w+|#\\w+', '', txt)\n",
    "    txt = re.sub(r'[^a-zA-Z\\s]', '', txt)\n",
    "    txt = txt.lower().strip()\n",
    "    return txt if len(txt.split()) > 2 else ''\n",
    "\n",
    "df_labeled['text'] = df_labeled['text'].apply(clean)\n",
    "df_labeled = df_labeled[df_labeled['text']!='']\n",
    "\n",
    "df_btc['text'] = df_btc['text'].apply(clean)\n",
    "df_btc = df_btc[df_btc['text']!='']\n",
    "print(\"Cleaned – labeled:\", len(df_labeled), \"btc:\", len(df_btc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa53cc",
   "metadata": {},
   "source": [
    "### HYPERPARAMETER SEARCH – 6 PROFESSIONAL-GRADE EXPERIMENTS\n",
    "\n",
    "\n",
    "We don't just train one model — we run a full ablation study:\n",
    "\n",
    "• 2 state-of-the-art architectures:\n",
    "       → FinBERT (finance-specialized, ProsusAI)\n",
    "       → RoBERTa-base (general-purpose SOTA)\n",
    "\n",
    "• 3 carefully designed training configurations:\n",
    "       A. Conservative  → low LR, small batch, 5 epochs\n",
    "       B. Balanced      → optimal speed/accuracy\n",
    "       C. Aggressive    → high LR, fast convergence\n",
    "\n",
    " Total: 6 independent training runs on full 5.8k labeled dataset\n",
    " Metrics: Weighted F1 Score (primary) + Accuracy\n",
    " Goal: Find the single best model for real-world Bitcoin sentiment\n",
    "\n",
    " The winner is automatically selected and used in the final dashboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d70d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from itertools import product\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    f1 = f1_score(p.label_ids, preds, average='weighted')\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "# Define 3 different training configurations\n",
    "configs = [\n",
    "    {\n",
    "        \"name\": \"Config A: Conservative\",\n",
    "        \"lr\": 1e-5,\n",
    "        \"batch_size\": 16,\n",
    "        \"epochs\": 5,\n",
    "        \"warmup\": 200,\n",
    "        \"weight_decay\": 0.01\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Config B: Balanced \",\n",
    "        \"lr\": 1.5e-5,\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 4,\n",
    "        \"warmup\": 100,\n",
    "        \"weight_decay\": 0.01\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Config C: Aggressive\",\n",
    "        \"lr\": 3e-5,\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 3,\n",
    "        \"warmup\": 50,\n",
    "        \"weight_decay\": 0.05\n",
    "    }\n",
    "]\n",
    "\n",
    "models_to_test = [\"ProsusAI/finbert\", \"roberta-base\"]\n",
    "results = []\n",
    "\n",
    "print(\"Starting 6-model hyperparameter search...\\n\")\n",
    "\n",
    "for model_name, config in product(models_to_test, configs):\n",
    "    short_name = \"FinBERT\" if \"finbert\" in model_name else \"RoBERTa\"\n",
    "    print(f\"Training {short_name} → {config['name']}...\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "    model.to(device)\n",
    "\n",
    "    # Split data\n",
    "    train_df = df_labeled.sample(frac=0.8, random_state=42)\n",
    "    val_df = df_labeled.drop(train_df.index)\n",
    "\n",
    "    def tokenize(batch):\n",
    "        return tokenizer(batch['text'], padding=True, truncation=True, max_length=128)\n",
    "\n",
    "    train_ds = Dataset.from_pandas(train_df).map(tokenize, batched=True)\n",
    "    val_ds = Dataset.from_pandas(val_df).map(tokenize, batched=True)\n",
    "    for ds in (train_ds, val_ds):\n",
    "        ds.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"./{short_name}_{config['name'].replace(' ', '_')}\",\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        learning_rate=config['lr'],\n",
    "        per_device_train_batch_size=config['batch_size'],\n",
    "        per_device_eval_batch_size=config['batch_size'],\n",
    "        num_train_epochs=config['epochs'],\n",
    "        weight_decay=config['weight_decay'],\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='f1',\n",
    "        warmup_steps=config['warmup'],\n",
    "        lr_scheduler_type='linear',\n",
    "        fp16=True,\n",
    "        report_to=[],\n",
    "        logging_steps=10,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_result = trainer.evaluate()\n",
    "\n",
    "    f1 = eval_result['eval_f1']\n",
    "    acc = eval_result['eval_accuracy']\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": short_name,\n",
    "        \"Config\": config['name'],\n",
    "        \"Learning Rate\": config['lr'],\n",
    "        \"Batch Size\": config['batch_size'],\n",
    "        \"Epochs\": config['epochs'],\n",
    "        \"F1 Score\": round(f1, 4),\n",
    "        \"Accuracy\": round(acc, 4),\n",
    "        \"Trainer\": trainer\n",
    "    })\n",
    "\n",
    "    print(f\"Done → F1: {f1:.4f}\\n\")\n",
    "\n",
    "\n",
    "#  FINAL COMPARISON TABLE\n",
    "\n",
    "results_df = pd.DataFrame(results).drop(columns=\"Trainer\")\n",
    "results_df = results_df.sort_values(\"F1 Score\", ascending=False).reset_index(drop=True)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL HYPERPARAMETER SEARCH RESULTS (6 Models)\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Select the BEST model\n",
    "best_row = results_df.iloc[0]\n",
    "best_trainer = [r[\"Trainer\"] for r in results if r[\"F1 Score\"] == best_row[\"F1 Score\"]][0]\n",
    "best_name = f\"{best_row['Model']} ({best_row['Config']})\"\n",
    "\n",
    "print(f\"\\nBEST MODEL SELECTED: {best_name}\")\n",
    "print(f\"→ F1 Score: {best_row['F1 Score']:.4f} | Accuracy: {best_row['Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e2951a",
   "metadata": {},
   "source": [
    "# Classify  Bitcoin tweets using the best model\n",
    "We:\n",
    "- Tokenize tweets using the best model’s tokenizer\n",
    "- Run inference on GPU\n",
    "- Assign labels: **Positive / Negative / Neutral**\n",
    "- Compute **total counts and percentages**\n",
    "- Display **one real example from each class**\n",
    "\n",
    "This shows both **overall trader mood** and **concrete evidence**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Clean tweets\n",
    "df_btc_clean = df_btc[df_btc['text'].apply(lambda x: isinstance(x, str) and len(x.strip()) > 0)].copy()\n",
    "print(f\"Clean BTC tweets: {len(df_btc_clean)}\")\n",
    "\n",
    "# Use the tokenizer from the best trainer (avoids deprecation warning)\n",
    "tokenizer = best_trainer.tokenizer\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch['text'],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "print(\"\\nTokenizing Bitcoin tweets...\")\n",
    "btc_ds = Dataset.from_pandas(df_btc_clean[['text']]).map(tokenize_batch, batched=True)\n",
    "btc_ds.set_format('torch', columns=['input_ids', 'attention_mask'])\n",
    "\n",
    "# Predict\n",
    "print(f\"Predicting with BEST MODEL: {best_name}...\")\n",
    "preds = best_trainer.predict(btc_ds)\n",
    "df_btc_clean['pred'] = preds.predictions.argmax(-1)\n",
    "df_btc_clean['sentiment'] = df_btc_clean['pred'].map({0: 'Positive', 1: 'Negative', 2: 'Neutral'})\n",
    "df_btc_clean['score'] = df_btc_clean['pred'].map({0: 1, 1: -1, 2: 0})\n",
    "\n",
    "# TOTAL COUNTS\n",
    "total = len(df_btc_clean)\n",
    "counts = df_btc_clean['sentiment'].value_counts()\n",
    "print(f\"\\nTOTAL CLASSIFICATION RESULTS ({best_name}):\")\n",
    "for label in ['Positive', 'Negative', 'Neutral']:\n",
    "    n = counts.get(label, 0)\n",
    "    pct = (n / total) * 100\n",
    "    print(f\"  {label:8}: {n:4} tweets ({pct:5.1f}%)\")\n",
    "\n",
    "# 1 SAMPLE FROM EACH CLASS\n",
    "print(f\"\\nBALANCED SAMPLE (1 of each sentiment):\")\n",
    "samples = []\n",
    "for label in ['Positive', 'Negative', 'Neutral']:\n",
    "    sample = df_btc_clean[df_btc_clean['sentiment'] == label].sample(1, random_state=42)\n",
    "    row = sample.iloc[0]\n",
    "    samples.append({\n",
    "        'date': row['date'].strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'text': row['text'],\n",
    "        'sentiment': row['sentiment']\n",
    "    })\n",
    "\n",
    "samples_df = pd.DataFrame(samples)\n",
    "print(samples_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef72132",
   "metadata": {},
   "source": [
    "# Visualize results with interactive charts\n",
    "We build a two-panel dashboard using Plotly:\n",
    "1. **Pie Chart** – % of Positive, Negative, Neutral tweets\n",
    "2. **Line Chart** – Daily net sentiment score over time  \n",
    "   (Positive = +1, Negative = -1, Neutral = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca2d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = df_btc_clean['sentiment'].value_counts(normalize=True) * 100\n",
    "df_btc_clean['day'] = df_btc_clean['date'].dt.date\n",
    "daily = df_btc_clean.groupby('day')['score'].mean().reset_index()\n",
    "daily['day'] = pd.to_datetime(daily['day'])\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=(f'Sentiment % ({best_name})', 'Daily Net Sentiment'),\n",
    "    specs=[[{\"type\":\"pie\"}, {\"type\":\"scatter\"}]]\n",
    ")\n",
    "fig.add_trace(go.Pie(labels=dist.index, values=dist.values,\n",
    "                     marker_colors=['#2ca02c','#d62728','#1f77b4'], hole=0.4), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=daily['day'], y=daily['score'],\n",
    "                         mode='lines+markers', line=dict(color='purple')), row=1, col=2)\n",
    "fig.update_layout(title_text=f\"Bitcoin Trader Sentiment – Best Model: {best_name}\", height=500)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
